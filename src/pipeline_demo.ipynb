{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed79f1c-2767-4d8d-8988-f7d1cf29ec72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import summary\n",
    "import yaml\n",
    "\n",
    "import Dataset\n",
    "import Models\n",
    "from utils import time_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a033a6e-d7e1-43a4-8556-ec00b1761f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.0.1+cu117\n",
      "Cuda available: False\n",
      "Cuda version: 11.7\n",
      "Torch geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Cuda device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Cuda version: {torch.version.cuda}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335227eb-02db-4fb9-85a6-4af3562ca297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32eb1309-2482-472b-aac9-799c45dca7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open('./config/pipeline.yaml'))\n",
    "\n",
    "DATA_PATH = params['input_subset_pre_processed']\n",
    "MESH_PATH = params['input_subset_grid']\n",
    "\n",
    "TRAIN_PROP = params['train_prop']\n",
    "VAL_PROP = params['val_prop']\n",
    "TEST_PROP = params['test_prop']\n",
    "\n",
    "TRAIN_BATCH_SIZE = params['train_batch_size']\n",
    "VAL_BATCH_SIZE = params['val_batch_size']\n",
    "TEST_BATCH_SIZE = params['test_batch_size']\n",
    "\n",
    "# TODO use these\n",
    "N_FEATURES = params['n_features']\n",
    "HID_CHANNELS = params['hid_channels']\n",
    "N_CLASSES = params['n_classes']\n",
    "\n",
    "FINAL_ACT = None\n",
    "if params['final_act'] == \"sigmoid\":\n",
    "    FINAL_ACT = torch.sigmoid\n",
    "elif params['final_act'] == \"linear\":\n",
    "    FINAL_ACT = torch.nn.Linear(1, 1)\n",
    "\n",
    "LOSS_OP = None\n",
    "if params['loss_op'] == \"BCE\":\n",
    "    LOSS_OP = torch.nn.BCELoss()\n",
    "\n",
    "OPTIMIZER = None\n",
    "if params['optimizer'] == \"Adam\":\n",
    "    OPTIMIZER = torch.optim.Adam\n",
    "\n",
    "LEARN_RATE = params['learn_rate']\n",
    "\n",
    "# TODO use these\n",
    "PLOT_SHOW = params['plot_show']\n",
    "PLOT_VERTICAL = params['plot_vertical']\n",
    "\n",
    "#TIMESTAMP = time_func.start_time() # TODO test for performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8009f87-209a-4138-9f7d-9428780d3b3f",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcbd3fe-b76f-49eb-9921-24a6013db352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  256  val:  73  test:  36\n",
      "(EddyDataset(256), tensor([245,  76, 144,  66,  34,  78,  62, 177, 184,  80, 252, 161, 148, 133,\n",
      "         91,  46, 158, 146,  59, 238, 106, 190, 134,   8,  61,  33, 174, 242,\n",
      "        232, 130,  52, 180, 152,  36,  10, 157, 233,  86, 187,  23,  35, 192,\n",
      "        163,   2,  68, 143, 243, 122, 109, 239, 231,  43, 105, 118, 203, 188,\n",
      "        202,  39, 179,  41,   1,  21, 244,  85, 166,  65,  97,  83,  67, 223,\n",
      "         63,  71, 121, 162, 175, 116, 120,  99,  88, 126, 213,  27,  51, 218,\n",
      "         28, 201,  20,  38, 251, 226,  69, 136, 186,  93,  90,  22,  49,  70,\n",
      "         17, 189,  98, 171,  72,  48, 160,  74, 247, 159, 167,  55, 183, 237,\n",
      "         16, 108, 209, 197, 200,  95, 129,  26,  87, 205, 229, 103,  24,   9,\n",
      "         19, 123,  45, 156,  79, 164, 222, 224,  44,  13, 119, 248, 194, 241,\n",
      "        199, 207, 221,  42,  73, 139, 254, 182, 168, 181, 142,  37,   7, 110,\n",
      "        137, 234, 150, 125, 127, 250, 176,  89,  40, 124, 219, 135,   3, 172,\n",
      "         54,  11, 107, 141, 225,  82,  84, 228, 216,  94,  56,   5,  18,  50,\n",
      "        204,   0, 198, 227, 214, 253, 246, 230,  75,  92, 115, 215, 178, 128,\n",
      "         81,  29, 153, 212, 208,  14, 151, 255, 114, 217, 132, 111, 112, 147,\n",
      "         15, 235, 196,   6,  32,  12, 149,  64, 193, 140,  31,  57, 220, 131,\n",
      "        104, 145,  60,  77, 117, 191, 101, 165, 240, 155, 154,  58, 169, 210,\n",
      "        100, 195, 102, 249, 170, 211, 113, 173, 138,  47,   4,  25, 185, 236,\n",
      "         53, 206,  30,  96]))\n",
      "shuffle x1\n",
      "train:  256  val:  73  test:  36\n",
      "train:  256  val:  73  test:  36\n",
      "  ---  Datasets creation  ---  0.189 seconds.\n"
     ]
    }
   ],
   "source": [
    "timestamp = time_func.start_time()\n",
    "train_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, split='train')\n",
    "val_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, split='val')\n",
    "test_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, split='test')\n",
    "time_func.stop_time(timestamp, \"Datasets creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e716ee0-b006-4e55-a44f-73a6e30de341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 73 36\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.len(), val_dataset.len(), test_dataset.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5f242e-536a-4030-868e-76c41aae95cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get(val): year_2015_month_11_day_2.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[757747, 1], edge_index=[2, 4537526], y=[757747])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65efdf-cfde-4feb-8cd3-f240636c1c34",
   "metadata": {},
   "source": [
    "### Testing some parameters and orientation of graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "764f45a6-dfe7-4fa7-b892-5dbc756db97c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get(train): year_2015_month_11_day_9.pt\n"
     ]
    }
   ],
   "source": [
    "if (TRAIN_PROP+VAL_PROP+TEST_PROP) != 100:\n",
    "    raise ValueError(f\"Sum of train-val-test proportions with value {TRAIN_PROP+VAL_PROP+TEST_PROP} is different from 1\")\n",
    "\n",
    "if FINAL_ACT == None:\n",
    "    raise ValueError(f\"Parameter 'final_act' is invalid with value {params['final_act']}\")\n",
    "\n",
    "if LOSS_OP == None:\n",
    "    raise ValueError(f\"Parameter 'loss_op' is invalid with value {params['loss_op']}\")\n",
    "\n",
    "if OPTIMIZER == None:\n",
    "    raise ValueError(f\"Parameter 'optimizer' is invalid with value {params['optimizer']}\")\n",
    "\n",
    "dummy_graph = train_dataset[0]\n",
    "\n",
    "if dummy_graph.num_features != N_FEATURES:\n",
    "    raise ValueError(f\"Graph num_features is different from parameter N_FEATURES: ({dummy_graph.num_features} != {N_FEATURES})\")\n",
    "\n",
    "if dummy_graph.is_directed():\n",
    "    raise ValueError(\"Graph edges are directed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b756f7-7799-4dc8-b40a-aaef3b1ce904",
   "metadata": {},
   "source": [
    "### Train-validation-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb48de5-b562-4ef0-a9bd-60c81a6e8e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train_set = []\n",
    "val_set = []\n",
    "test_set = []\n",
    "train_months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "val_months = [11]\n",
    "test_months = [12]\n",
    "\n",
    "for m in train_months:\n",
    "    train_set += dataset.get_all(year=2015, month=m)\n",
    "    print(m)\n",
    "    \n",
    "for m in val_months:\n",
    "    val_set += dataset.get_all(year=2015, month=m)\n",
    "    print(m)\n",
    "\n",
    "for m in test_months:\n",
    "    test_set += dataset.get_all(year=2015, month=m)\n",
    "    print(m)\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_set))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=VAL_BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d40cf8d-1eb2-4177-9830-0fac421de7de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 73 36\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3de1d-9864-4536-b634-e05635056e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6db1ea-a1d4-4793-a665-838c3df37dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUNet instantiated!\n",
      "\tMiddle act: relu\n",
      "\tFinal act: torch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GUNet(\n",
       "  (unet): GraphUNet(1, 32, 1, depth=3, pool_ratios=[0.002639403389257892, 0.5, 0.5])\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = Models.GUNet\n",
    "\n",
    "model = Model(\n",
    "    in_channels = N_FEATURES,\n",
    "    hidden_channels = HID_CHANNELS,\n",
    "    out_channels = N_CLASSES,\n",
    "    num_nodes = dummy_graph.num_nodes,   # TODO can put these in Dataset.py\n",
    "    final_act = FINAL_ACT\n",
    ").to(DEVICE)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b39dc66b-4924-4ada-862c-e75be6e678f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/b382485/miniconda3/envs/eddy-tracking/lib/python3.8/site-packages/torch_sparse/matmul.py:97: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  C = torch.sparse.mm(A, B)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'+-------------------------------+---------------------------------------------------+---------------------------------------------------------+----------+\\n| Layer                         | Input Shape                                       | Output Shape                                            | #Param   |\\n|-------------------------------+---------------------------------------------------+---------------------------------------------------------+----------|\\n| GUNet                         | [757747, 757747]                                  | [757747, 1]                                             | 5,473    |\\n| ├─(unet)GraphUNet             | [757747, 1], [2, 4537526]                         | [757747, 1]                                             | 5,473    |\\n| │    └─(down_convs)ModuleList | --                                                | --                                                      | 3,232    |\\n| │    │    └─(0)GCNConv        | [757747, 1], [2, 4537526], [4537526]              | [757747, 32]                                            | 64       |\\n| │    │    └─(1)GCNConv        | [2000, 32], [2, 12242], [12242]                   | [2000, 32]                                              | 1,056    |\\n| │    │    └─(2)GCNConv        | [1000, 32], [2, 7966], [7966]                     | [1000, 32]                                              | 1,056    |\\n| │    │    └─(3)GCNConv        | [500, 32], [2, 5318], [5318]                      | [500, 32]                                               | 1,056    |\\n| │    └─(pools)ModuleList      | --                                                | --                                                      | 96       |\\n| │    │    └─(0)TopKPooling    | [757747, 32], [2, 13616956], [13616956], [757747] | [2000, 32], [2, 12242], [12242], [2000], [2000], [2000] | 32       |\\n| │    │    └─(1)TopKPooling    | [2000, 32], [2, 20970], [20970], [2000]           | [1000, 32], [2, 7966], [7966], [1000], [1000], [1000]   | 32       |\\n| │    │    └─(2)TopKPooling    | [1000, 32], [2, 12364], [12364], [1000]           | [500, 32], [2, 5318], [5318], [500], [500], [500]       | 32       |\\n| │    └─(up_convs)ModuleList   | --                                                | --                                                      | 2,145    |\\n| │    │    └─(0)GCNConv        | [1000, 32], [2, 7966], [7966]                     | [1000, 32]                                              | 1,056    |\\n| │    │    └─(1)GCNConv        | [2000, 32], [2, 12242], [12242]                   | [2000, 32]                                              | 1,056    |\\n| │    │    └─(2)GCNConv        | [757747, 32], [2, 4537526], [4537526]             | [757747, 1]                                             | 33       |\\n+-------------------------------+---------------------------------------------------+---------------------------------------------------------+----------+'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, dummy_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09936-0b86-4ac6-83a9-014239ce3675",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c4bc3e-ff40-44eb-8e85-21bf090eaa05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr=0.005)# = OPTIMIZER(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dba108-aab1-4308-8ef1-f9af1595b818",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba5d99c5-5c07-494b-8eb4-849741d46173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get(train): year_2015_month_11_day_17.pt\n",
      "Get(train): year_2015_month_8_day_11.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n\u001b[0;32m---> 31\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mLOSS_OP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# If you try the Soft Dice Score, use this(even if the loss stays constant)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#loss.requires_grad = True\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#loss = torch.tensor(loss.item(), requires_grad=True)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# backward + optimize\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# loss * _train_batch_size(5)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking/lib/python3.8/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking/lib/python3.8/site-packages/torch/nn/functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3096\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        pred = pred.squeeze()\n",
    "\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "\n",
    "        # If you try the Soft Dice Score, use this(even if the loss stays constant)\n",
    "        #loss.requires_grad = True\n",
    "        #loss = torch.tensor(loss.item(), requires_grad=True)\n",
    "\n",
    "        # backward + optimize\n",
    "        # loss * _train_batch_size(5)\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # average loss = total_loss / training graps(20)\n",
    "    total_loss = total_loss / len(train_loader.dataset)\n",
    "    return total_loss\n",
    "\n",
    "loss = train()\n",
    "#print(\"Train loss, debug: \", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd280d25-79bc-4f0e-b386-879a6107eeca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy-tracking",
   "language": "python",
   "name": "eddy-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
