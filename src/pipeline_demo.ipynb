{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed79f1c-2767-4d8d-8988-f7d1cf29ec72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import summary\n",
    "import xarray as xr\n",
    "\n",
    "import yaml\n",
    "import Dataset\n",
    "import Models\n",
    "import Loss\n",
    "from utils import time_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a033a6e-d7e1-43a4-8556-ec00b1761f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.0+cu121\n",
      "Cuda available: True\n",
      "Cuda device: NVIDIA A100-SXM4-40GB\n",
      "Cuda version: 12.1\n",
      "Torch geometric version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Cuda device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Cuda version: {torch.version.cuda}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335227eb-02db-4fb9-85a6-4af3562ca297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32eb1309-2482-472b-aac9-799c45dca7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open('./config/pipeline.yaml'))\n",
    "\n",
    "DATA_PATH = params['input_subset_pre_processed']\n",
    "MESH_PATH = params['input_subset_grid']\n",
    "\n",
    "DATASET_SIZE = params['dataset_size']\n",
    "\n",
    "TRAIN_PROP = params['train_prop']\n",
    "VAL_PROP = params['val_prop']\n",
    "TEST_PROP = params['test_prop']\n",
    "TRAIN_VAL_TEST = [TRAIN_PROP, VAL_PROP, TEST_PROP]\n",
    "\n",
    "TRAIN_BATCH_SIZE = params['train_batch_size']\n",
    "VAL_BATCH_SIZE = params['val_batch_size']\n",
    "TEST_BATCH_SIZE = params['test_batch_size']\n",
    "\n",
    "N_FEATURES = params['n_features']\n",
    "HID_CHANNELS = params['hid_channels']\n",
    "N_CLASSES = params['n_classes']\n",
    "N_LAYERS = params['n_layers']\n",
    "MODEL_USED = params['model_used']\n",
    "\n",
    "FINAL_ACT = None\n",
    "if params['final_act'] == \"sigmoid\":\n",
    "    FINAL_ACT = torch.sigmoid\n",
    "elif params['final_act'] == \"softmax\":\n",
    "    FINAL_ACT = torch.softmax\n",
    "elif params['final_act'] == \"linear\":\n",
    "    FINAL_ACT = torch.nn.Linear(1, 1)\n",
    "\n",
    "LOSS_OP = None\n",
    "class_weights = [params['loss_weight_1'], params['loss_weight_2'], params['loss_weight_3']]\n",
    "#class_weights = torch.tensor([0.0238, 0.5028, 0.4734], dtype=torch.float32)\n",
    "if params['loss_op'] == \"CE\":\n",
    "    LOSS_OP = torch.nn.CrossEntropyLoss()\n",
    "elif params['loss_op'] == \"WCE\":\n",
    "    LOSS_OP = Loss.WeightedCrossEntropyLoss(class_weights)\n",
    "elif params['loss_op'] == \"Dice\":\n",
    "    LOSS_OP = Loss.SoftDiceLoss()\n",
    "elif params['loss_op'] == \"WDice\":\n",
    "    #class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    LOSS_OP = Loss.WeightedSoftDiceLossMultiClass(class_weights)\n",
    "\n",
    "OPTIMIZER = None\n",
    "if params['optimizer'] == \"Adam\":\n",
    "    OPTIMIZER = torch.optim.Adam\n",
    "\n",
    "LEARN_RATE = params['learn_rate']\n",
    "\n",
    "EPOCHS = params['epochs']\n",
    "\n",
    "PLOT_SHOW = params['plot_show']\n",
    "PLOT_FOLDER = params['output_images_path']\n",
    "\n",
    "TIMESTAMP = time_func.start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8009f87-209a-4138-9f7d-9428780d3b3f",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcbd3fe-b76f-49eb-9921-24a6013db352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for train-val-test split: 4000\n",
      "    Shape of node feature matrix: torch.Size([239536, 1])\n",
      "    Shape of graph connectivity in COO format: torch.Size([2, 1432160])\n",
      "    Shape of labels: torch.Size([239536])\n",
      "  ---  Datasets creation  ---  4.620 seconds.\n"
     ]
    }
   ],
   "source": [
    "random_seed = random.randint(1, 10000)\n",
    "print(f\"Random seed for train-val-test split: {random_seed}\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='train', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "val_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='val', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "test_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='test', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Datasets creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e716ee0-b006-4e55-a44f-73a6e30de341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155 231 154\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.len(), val_dataset.len(), test_dataset.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65efdf-cfde-4feb-8cd3-f240636c1c34",
   "metadata": {},
   "source": [
    "### Testing some parameters and orientation of graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764f45a6-dfe7-4fa7-b892-5dbc756db97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (TRAIN_PROP+VAL_PROP+TEST_PROP) != 100:\n",
    "    raise ValueError(f\"Sum of train-val-test proportions with value {TRAIN_PROP+VAL_PROP+TEST_PROP} is different from 100\")\n",
    "\n",
    "if FINAL_ACT == None:\n",
    "    raise ValueError(f\"Parameter 'final_act' is invalid with value {params['final_act']}\")\n",
    "\n",
    "if LOSS_OP == None:\n",
    "    raise ValueError(f\"Parameter 'loss_op' is invalid with value {params['loss_op']}\")\n",
    "\n",
    "if OPTIMIZER == None:\n",
    "    raise ValueError(f\"Parameter 'optimizer' is invalid with value {params['optimizer']}\")\n",
    "\n",
    "dummy_graph = train_dataset[0]\n",
    "\n",
    "if dummy_graph.num_features != N_FEATURES:\n",
    "    raise ValueError(f\"Graph num_features is different from parameter N_FEATURES: ({dummy_graph.num_features} != {N_FEATURES})\")\n",
    "\n",
    "if dummy_graph.is_directed():\n",
    "    raise ValueError(\"Graph edges are directed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b756f7-7799-4dc8-b40a-aaef3b1ce904",
   "metadata": {},
   "source": [
    "### Train-validation-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d40cf8d-1eb2-4177-9830-0fac421de7de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155 231 154\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3de1d-9864-4536-b634-e05635056e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6db1ea-a1d4-4793-a665-838c3df37dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGEModel(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): SAGEConv(1, 64, aggr=mean)\n",
       "    (1-30): 30 x SAGEConv(64, 64, aggr=mean)\n",
       "    (31): SAGEConv(64, 3, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if MODEL_USED == \"UNET\":\n",
    "    Model = Models.GUNet\n",
    "    model = Model(\n",
    "        in_channels = N_FEATURES,\n",
    "        hidden_channels = N_CLASSES,\n",
    "        out_channels = N_CLASSES,\n",
    "        num_nodes = dummy_graph.num_nodes,   # TODO can put these in Dataset.py\n",
    "        final_act = FINAL_ACT\n",
    "    ).to(DEVICE)\n",
    "elif MODEL_USED == \"GCN\":\n",
    "    Model = Models.GCNModel\n",
    "    model = Model(\n",
    "        in_channels = N_FEATURES,\n",
    "        hidden_channels = HID_CHANNELS,\n",
    "        out_channels = N_CLASSES,\n",
    "        num_layers = N_LAYERS,\n",
    "        num_nodes = dummy_graph.num_nodes   # TODO can put these in Dataset.py\n",
    "        #final_act = FINAL_ACT\n",
    "    ).to(DEVICE)\n",
    "elif MODEL_USED == \"SAGE\":\n",
    "    Model = Models.GraphSAGEModel\n",
    "    model = Model(\n",
    "        num_features = N_FEATURES,\n",
    "        hidden_dim = HID_CHANNELS,\n",
    "        num_classes = N_CLASSES,\n",
    "        num_layers = N_LAYERS\n",
    "        #num_nodes = dummy_graph.num_nodes   # TODO can put these in Dataset.py\n",
    "        #final_act = FINAL_ACT\n",
    "    ).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39dc66b-4924-4ada-862c-e75be6e678f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------------------------+----------------+----------+\n",
      "| Layer                     | Input Shape                | Output Shape   | #Param   |\n",
      "|---------------------------+----------------------------+----------------+----------|\n",
      "| GraphSAGEModel            | [239536, 239536]           | [239536, 3]    | 248,259  |\n",
      "| ├─(conv_layers)ModuleList | --                         | --             | 248,259  |\n",
      "| │    └─(0)SAGEConv        | [239536, 1], [2, 1432160]  | [239536, 64]   | 192      |\n",
      "| │    └─(1)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(2)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(3)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(4)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(5)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(6)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(7)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(8)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(9)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(10)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(11)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(12)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(13)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(14)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(15)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(16)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(17)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(18)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(19)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(20)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(21)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(22)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(23)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(24)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(25)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(26)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(27)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(28)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(29)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(30)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(31)SAGEConv       | [239536, 64], [2, 1432160] | [239536, 3]    | 387      |\n",
      "+---------------------------+----------------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "num_nodes = dummy_graph.num_nodes\n",
    "dummy_graph.to(DEVICE)\n",
    "print(summary(model, dummy_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09936-0b86-4ac6-83a9-014239ce3675",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c4bc3e-ff40-44eb-8e85-21bf090eaa05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = OPTIMIZER(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dba108-aab1-4308-8ef1-f9af1595b818",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5d99c5-5c07-494b-8eb4-849741d46173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "\n",
    "        # If you try the Soft Dice Score, use this(even if the loss stays constant)\n",
    "        #loss.requires_grad = True\n",
    "        #loss = torch.tensor(loss.item(), requires_grad=True)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        \n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191eccf-0b3e-4e2f-9eb8-d0b68e2f5aa8",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c067d1ee-f24b-41e5-8fd4-6de0f9546ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    \n",
    "    average_loss = total_loss / len(loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c0bd0-d87d-407a-a00f-c3b1baeb6075",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computation time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5fb713-fda3-40bd-b729-be63ec773546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ---  Computation before training finished!  ---  5.962 seconds.\n"
     ]
    }
   ],
   "source": [
    "time_func.stop_time(TIMESTAMP, \"Computation before training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e39fb6f-6f39-4071-9271-ae684ba04d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom time import time\\nimport multiprocessing as mp\\n\\nfor num_workers in range(2, mp.cpu_count(), 2):\\n    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\\n    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\\n\\n    start = time()\\n    for epoch in range(1, 3):\\n        for i, data in enumerate(train_loader, 0):\\n            pass\\n        for i, data in enumerate(val_loader, 0):\\n            pass\\n    end = time()\\n    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "for num_workers in range(2, mp.cpu_count(), 2):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8995f5-2bb4-4fee-bc5d-523333087f5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Epoch training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa97935-88b2-411b-aec5-c21441b0d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.40 GiB is free. Including non-PyTorch memory, this process has 34.94 GiB memory in use. Of the allocated memory 25.32 GiB is allocated by PyTorch, and 9.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 7\u001b[0m     t_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     v_loss \u001b[38;5;241m=\u001b[39m evaluate(val_loader)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train running loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val running loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# forward + loss\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m LOSS_OP(pred, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# If you try the Soft Dice Score, use this(even if the loss stays constant)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#loss.requires_grad = True\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#loss = torch.tensor(loss.item(), requires_grad=True)\u001b[39;00m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/eddiesGNN/src/Models.py:102\u001b[0m, in \u001b[0;36mGraphSAGEModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     99\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m--> 102\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    105\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:130\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    127\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    133\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:455\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    453\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 455\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:329\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 329\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:276\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an index error. Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got interval \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound negative indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking-gpu/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:266\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.46 GiB. GPU 0 has a total capacty of 39.39 GiB of which 4.40 GiB is free. Including non-PyTorch memory, this process has 34.94 GiB memory in use. Of the allocated memory 25.32 GiB is allocated by PyTorch, and 9.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t_loss = train()\n",
    "    v_loss = evaluate(val_loader)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train running loss: {t_loss:.4f}, Val running loss: {v_loss:.4f}')\n",
    "    train_loss.append(t_loss)\n",
    "    valid_loss.append(v_loss)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Training Complete!\")\n",
    "\n",
    "metric = evaluate(test_loader)\n",
    "print(f'Metric for test: {metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07469213-20da-4a74-9219-4521d40a3855",
   "metadata": {},
   "source": [
    "### Comparison plot for train/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d123bb-cdf2-42fc-856a-cbed3dcf6c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(valid_loss, label='Validation loss')\n",
    "plt.legend(title=\"Loss type: \" + params['loss_op'])\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER+\"/train_val_losses_demo.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe13b1a-e3c5-475b-a213-c1bb1b7dbc8b",
   "metadata": {},
   "source": [
    "### Graphical comparison model prediction/ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d84f40-be8b-4000-b687-0c1e3683f218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "DEVICE=torch.device('cpu')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e033e-9969-491a-ab5e-28800642c34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    batch = batch.to(DEVICE)\n",
    "    pred = model(batch)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c03a6e-5ec6-477c-8861-df5e4c0cba1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mesh = xr.open_dataset(MESH_PATH)\n",
    "mesh_lon = mesh.lon[mesh.nodes].values\n",
    "mesh_lat = mesh.lat[mesh.nodes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb4196-350b-4cbc-b531-5856a8e45d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "this_target = batch.y[:mesh.dims['nodes_subset']]\n",
    "this_pred = []\n",
    "for p in pred[:mesh.dims['nodes_subset']]:\n",
    "    p = p.tolist()\n",
    "    max_value = max(p)\n",
    "    max_index = p.index(max_value)\n",
    "    this_pred.append(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3880b4f-68e4-4e14-a327-8fa3bd407277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "im = axes[0].scatter(mesh_lon, mesh_lat, c=this_target, s=1)\n",
    "im2 = axes[1].scatter(mesh_lon, mesh_lat, c=this_pred, s=1)\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER + \"/pred_vs_ground_demo.png\")\n",
    "    plt.close()\n",
    "\n",
    "time_func.stop_time(timestamp, \"pred_vs_ground plot created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015415e-df6a-4d72-9239-0cdd6c971e96",
   "metadata": {},
   "source": [
    "### Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e5b16-2487-413d-9dc1-94fdb6eb63a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running it on cuda is a huge improvement\n",
    "DEVICE=torch.device('cuda')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3276d-c915-48e5-96a6-bff9b4451509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tot_background = 0\n",
    "    correct_pred = 0\n",
    "    tot_pred = len(test_loader.dataset)*dummy_graph.num_nodes\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        pred = model(batch)\n",
    "\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "\n",
    "        tot_background += (batch.y == 0).sum().item()\n",
    "\n",
    "        # This works because the values in the indices correspond to the values in batch.y\n",
    "        correct_pred += (indices == batch.y).sum().item()\n",
    "\n",
    "    print(f\"Total background cells:\\t{tot_background}\")\n",
    "    print(f\"Correct predictions:\\t{correct_pred}\")\n",
    "    print(f\"Total predictions:\\t{tot_pred}\")\n",
    "    print(f\"Graph U-Net accuracy:\\t{correct_pred/tot_pred*100:.2f}%\")\n",
    "\n",
    "time_func.stop_time(timestamp, \"Accuracy calculated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb9f42-37b2-4f3c-a4da-32a30acc501f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07945aa5-344a-4a31-ba91-9898ff632482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy-tracking-gpu",
   "language": "python",
   "name": "eddy-tracking-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
