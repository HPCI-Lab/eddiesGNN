{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed79f1c-2767-4d8d-8988-f7d1cf29ec72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import summary\n",
    "import xarray as xr\n",
    "import yaml\n",
    "\n",
    "import Dataset\n",
    "import Models\n",
    "import Loss\n",
    "from utils import time_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a033a6e-d7e1-43a4-8556-ec00b1761f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.0+cu121\n",
      "Cuda available: True\n",
      "Cuda device: NVIDIA A100-SXM4-40GB\n",
      "Cuda version: 12.1\n",
      "Torch geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Cuda device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Cuda version: {torch.version.cuda}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335227eb-02db-4fb9-85a6-4af3562ca297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32eb1309-2482-472b-aac9-799c45dca7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open('./config/pipeline.yaml'))\n",
    "\n",
    "DATA_PATH = params['input_subset_pre_processed']\n",
    "MESH_PATH = params['input_subset_grid']\n",
    "\n",
    "DATASET_SIZE = params['dataset_size']\n",
    "\n",
    "TRAIN_PROP = params['train_prop']\n",
    "VAL_PROP = params['val_prop']\n",
    "TEST_PROP = params['test_prop']\n",
    "TRAIN_VAL_TEST = [TRAIN_PROP, VAL_PROP, TEST_PROP]\n",
    "\n",
    "TRAIN_BATCH_SIZE = params['train_batch_size']\n",
    "VAL_BATCH_SIZE = params['val_batch_size']\n",
    "TEST_BATCH_SIZE = params['test_batch_size']\n",
    "\n",
    "N_FEATURES = params['n_features']\n",
    "HID_CHANNELS = params['hid_channels']\n",
    "N_CLASSES = params['n_classes']\n",
    "\n",
    "FINAL_ACT = None\n",
    "if params['final_act'] == \"sigmoid\":\n",
    "    FINAL_ACT = torch.sigmoid\n",
    "elif params['final_act'] == \"softmax\":\n",
    "    FINAL_ACT = torch.softmax\n",
    "elif params['final_act'] == \"linear\":\n",
    "    FINAL_ACT = torch.nn.Linear(1, 1)\n",
    "\n",
    "LOSS_OP = None\n",
    "if params['loss_op'] == \"CE\":\n",
    "    LOSS_OP = torch.nn.CrossEntropyLoss()\n",
    "elif params['loss_op'] == \"WCE\":\n",
    "    class_weights = [params['loss_weight_1'], params['loss_weight_2'], params['loss_weight_3']]\n",
    "    LOSS_OP = Loss.WeightedCrossEntropyLoss(class_weights, DEVICE)\n",
    "\n",
    "OPTIMIZER = None\n",
    "if params['optimizer'] == \"Adam\":\n",
    "    OPTIMIZER = torch.optim.Adam\n",
    "\n",
    "LEARN_RATE = params['learn_rate']\n",
    "\n",
    "EPOCHS = params['epochs']\n",
    "\n",
    "PLOT_SHOW = params['plot_show']\n",
    "PLOT_FOLDER = params['output_images_path']\n",
    "\n",
    "TIMESTAMP = time_func.start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8009f87-209a-4138-9f7d-9428780d3b3f",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcbd3fe-b76f-49eb-9921-24a6013db352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for train-val-test split: 5454\n",
      "    Shape of node feature matrix: torch.Size([239536, 1])\n",
      "    Shape of graph connectivity in COO format: torch.Size([2, 1432160])\n",
      "    Shape of labels: torch.Size([239536])\n",
      "  ---  Datasets creation  ---  14.308 seconds.\n"
     ]
    }
   ],
   "source": [
    "random_seed = random.randint(1, 10000)\n",
    "print(f\"Random seed for train-val-test split: {random_seed}\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='train', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "val_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='val', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "test_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='test', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Datasets creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e716ee0-b006-4e55-a44f-73a6e30de341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 20 20\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.len(), val_dataset.len(), test_dataset.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a9bc78-057a-40af-a400-8e36e1f95f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataset[0]\\n\\ntimestamp = time_func.start_time()\\nfeatures_list = [data.x for data in train_dataset]\\nprint(np.shape(features_list))\\ntime_func.stop_time(timestamp, \"features in a list!\")\\n\\ntimestamp = time_func.start_time()\\nall_features = torch.cat(features_list, dim=0)\\ntime_func.stop_time(timestamp, \"features concatenated!\")\\n\\nall_features.shape\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dataset[0]\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "features_list = [data.x for data in train_dataset]\n",
    "print(np.shape(features_list))\n",
    "time_func.stop_time(timestamp, \"features in a list!\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "all_features = torch.cat(features_list, dim=0)\n",
    "time_func.stop_time(timestamp, \"features concatenated!\")\n",
    "\n",
    "all_features.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4aa208-7f54-4ee7-8a40-cfd179636e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nglobal_mean = all_features.mean(dim=0)\\nglobal_std = all_features.std(dim=0)\\nprint(f\"Mean: {global_mean}\\nStd: {global_std}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "global_mean = all_features.mean(dim=0)\n",
    "global_std = all_features.std(dim=0)\n",
    "print(f\"Mean: {global_mean}\\nStd: {global_std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fdc3a82-7a16-4c77-b0e7-a14bce563fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torch_geometric.transforms import NormalizeFeatures\\ntransform = NormalizeFeatures()\\n\\nprint(train_dataset[0].x)\\n\\ntimestamp = time_func.start_time()\\n\\ntrain_dataset = [transform(data) for data in train_dataset]\\nval_dataset = [transform(data) for data in val_dataset]\\ntest_dataset = [transform(data) for data in test_dataset]\\n\\ntime_func.stop_time(timestamp, \"features normalized!\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "transform = NormalizeFeatures()\n",
    "\n",
    "print(train_dataset[0].x)\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = [transform(data) for data in train_dataset]\n",
    "val_dataset = [transform(data) for data in val_dataset]\n",
    "test_dataset = [transform(data) for data in test_dataset]\n",
    "\n",
    "time_func.stop_time(timestamp, \"features normalized!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10ebd8a-3705-41c5-81a2-a0711bafc7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = [data.x for data in train_dataset]\\nall_features = torch.cat(features, dim=0)\\nmean = all_features.mean(dim=0)\\nstd = all_features.std(dim=0)\\nprint(f\"Mean: {mean}\\nStd: {std}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "features = [data.x for data in train_dataset]\n",
    "all_features = torch.cat(features, dim=0)\n",
    "mean = all_features.mean(dim=0)\n",
    "std = all_features.std(dim=0)\n",
    "print(f\"Mean: {mean}\\nStd: {std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65efdf-cfde-4feb-8cd3-f240636c1c34",
   "metadata": {},
   "source": [
    "### Testing some parameters and orientation of graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764f45a6-dfe7-4fa7-b892-5dbc756db97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (TRAIN_PROP+VAL_PROP+TEST_PROP) != 100:\n",
    "    raise ValueError(f\"Sum of train-val-test proportions with value {TRAIN_PROP+VAL_PROP+TEST_PROP} is different from 100\")\n",
    "\n",
    "if FINAL_ACT == None:\n",
    "    raise ValueError(f\"Parameter 'final_act' is invalid with value {params['final_act']}\")\n",
    "\n",
    "if LOSS_OP == None:\n",
    "    if params['loss_op'] != \"Dice\":\n",
    "        raise ValueError(f\"Parameter 'loss_op' is invalid with value {params['loss_op']}\")\n",
    "\n",
    "if OPTIMIZER == None:\n",
    "    raise ValueError(f\"Parameter 'optimizer' is invalid with value {params['optimizer']}\")\n",
    "\n",
    "dummy_graph = train_dataset[0]\n",
    "\n",
    "if dummy_graph.num_features != N_FEATURES:\n",
    "    raise ValueError(f\"Graph num_features is different from parameter N_FEATURES: ({dummy_graph.num_features} != {N_FEATURES})\")\n",
    "\n",
    "if dummy_graph.is_directed():\n",
    "    raise ValueError(\"Graph edges are directed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b756f7-7799-4dc8-b40a-aaef3b1ce904",
   "metadata": {},
   "source": [
    "### Train-validation-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d40cf8d-1eb2-4177-9830-0fac421de7de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 20 20\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3de1d-9864-4536-b634-e05635056e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6db1ea-a1d4-4793-a665-838c3df37dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUNet instantiated!\n",
      "\tMiddle act: relu\n",
      "\tFinal act: softmax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GUNet(\n",
       "  (unet): GraphUNet(1, 64, 3, depth=3, pool_ratios=[0.008349475652928996, 0.5, 0.5])\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = Models.GUNet\n",
    "\n",
    "model = Model(\n",
    "    in_channels = N_FEATURES,\n",
    "    hidden_channels = HID_CHANNELS,\n",
    "    out_channels = N_CLASSES,\n",
    "    num_nodes = dummy_graph.num_nodes,   # TODO can put these in Dataset.py\n",
    "    final_act = FINAL_ACT\n",
    ").to(DEVICE)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39dc66b-4924-4ada-862c-e75be6e678f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------------------------------------+-------------------------------------+----------+\n",
      "| Layer                         | Input Shape                                     | Output Shape                        | #Param   |\n",
      "|-------------------------------+-------------------------------------------------+-------------------------------------+----------|\n",
      "| GUNet                         | [239536, 239536]                                | [239536, 3]                         | 21,315   |\n",
      "| ├─(unet)GraphUNet             | [239536, 1], [2, 1432160]                       | [239536, 3]                         | 21,315   |\n",
      "| │    └─(down_convs)ModuleList | --                                              | --                                  | 12,608   |\n",
      "| │    │    └─(0)GCNConv        | [239536, 1], [2, 1432160], [1432160]            | [239536, 64]                        | 128      |\n",
      "| │    │    └─(1)GCNConv        | [1, 64], [2, 0], [0]                            | [1, 64]                             | 4,160    |\n",
      "| │    │    └─(2)GCNConv        | [1, 64], [2, 0], [0]                            | [1, 64]                             | 4,160    |\n",
      "| │    │    └─(3)GCNConv        | [1, 64], [2, 0], [0]                            | [1, 64]                             | 4,160    |\n",
      "| │    └─(pools)ModuleList      | --                                              | --                                  | 192      |\n",
      "| │    │    └─(0)TopKPooling    | [239536, 64], [2, 4295280], [4295280], [239536] | [1, 64], [2, 0], [0], [1], [1], [1] | 64       |\n",
      "| │    │    └─(1)TopKPooling    | [1, 64], [2, 0], [0], [1]                       | [1, 64], [2, 0], [0], [1], [1], [1] | 64       |\n",
      "| │    │    └─(2)TopKPooling    | [1, 64], [2, 0], [0], [1]                       | [1, 64], [2, 0], [0], [1], [1], [1] | 64       |\n",
      "| │    └─(up_convs)ModuleList   | --                                              | --                                  | 8,515    |\n",
      "| │    │    └─(0)GCNConv        | [1, 64], [2, 0], [0]                            | [1, 64]                             | 4,160    |\n",
      "| │    │    └─(1)GCNConv        | [1, 64], [2, 0], [0]                            | [1, 64]                             | 4,160    |\n",
      "| │    │    └─(2)GCNConv        | [239536, 64], [2, 1432160], [1432160]           | [239536, 3]                         | 195      |\n",
      "+-------------------------------+-------------------------------------------------+-------------------------------------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/b382485/miniconda3/envs/eddy-tracking-new/lib/python3.11/site-packages/torch_geometric/utils/sparse.py:176: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return adj.to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "dummy_graph.to(DEVICE)\n",
    "print(summary(model, dummy_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09936-0b86-4ac6-83a9-014239ce3675",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c4bc3e-ff40-44eb-8e85-21bf090eaa05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = OPTIMIZER(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3a2a4-6840-412e-a0fb-17c9b68faecc",
   "metadata": {},
   "source": [
    "### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3555c5e-5132-4c9e-ac2f-93d626e96c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ---  Unique counted!  ---  10.257 seconds.\n",
      "[1.1445525188525638, 15.256814973634997, 16.460466458679786] - freq_inv\n",
      "[0.03482923444118693, 0.4642715618460798, 0.5008992037127332] - class_weights\n"
     ]
    }
   ],
   "source": [
    "if params['loss_op'] == \"Dice\":\n",
    "    \n",
    "    timestamp = time_func.start_time()\n",
    "\n",
    "    tot_counts = [0, 0, 0]\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        \n",
    "        unique, counts = torch.unique(batch.y, return_counts=True)\n",
    "        \n",
    "        # TODO - I don't really like this, it just informs me whether something is wrong and then does it anyway\n",
    "        if 0 not in unique:\n",
    "            print(\"Error: class 0 not present in batch\")\n",
    "        elif 1 not in unique:\n",
    "            print(\"Error: class 1 not present in batch\")\n",
    "        elif 2 not in unique:\n",
    "            print(\"Error: class 2 not present in batch\")\n",
    "        else:\n",
    "            for class_idx in unique:\n",
    "                tot_counts[class_idx] += counts[class_idx].item()\n",
    "\n",
    "    time_func.stop_time(timestamp, \"Unique counted!\")\n",
    "    \n",
    "    freq = [c/np.sum(tot_counts) for c in tot_counts]\n",
    "    freq_inv = [1/f for f in freq]\n",
    "    class_weights = [f/np.sum(freq_inv) for f in freq_inv]\n",
    "    print(freq_inv, \"- freq_inv\")\n",
    "    print(class_weights, \"- class_weights\")\n",
    "    LOSS_OP = Loss.SoftDiceLoss(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dba108-aab1-4308-8ef1-f9af1595b818",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5d99c5-5c07-494b-8eb4-849741d46173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "        \n",
    "        # If you try the Soft Dice Score, use this(even if the loss stays constant)\n",
    "        #loss.requires_grad = True\n",
    "        #loss = torch.tensor(loss.item(), requires_grad=True)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        \n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191eccf-0b3e-4e2f-9eb8-d0b68e2f5aa8",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c067d1ee-f24b-41e5-8fd4-6de0f9546ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    \n",
    "    average_loss = total_loss / len(loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c0bd0-d87d-407a-a00f-c3b1baeb6075",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computation time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5fb713-fda3-40bd-b729-be63ec773546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ---  Computation before training finished!  ---  25.736 seconds.\n"
     ]
    }
   ],
   "source": [
    "time_func.stop_time(TIMESTAMP, \"Computation before training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e39fb6f-6f39-4071-9271-ae684ba04d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom time import time\\nimport multiprocessing as mp\\n\\nfor num_workers in range(2, mp.cpu_count(), 2):\\n    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\\n    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\\n\\n    start = time()\\n    for epoch in range(1, 3):\\n        for i, data in enumerate(train_loader, 0):\\n            pass\\n        for i, data in enumerate(val_loader, 0):\\n            pass\\n    end = time()\\n    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "for num_workers in range(2, mp.cpu_count(), 2):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8995f5-2bb4-4fee-bc5d-523333087f5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Epoch training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa97935-88b2-411b-aec5-c21441b0d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train running loss: 0.8804, Val running loss: 0.8747\n",
      "Epoch: 002, Train running loss: 0.8784, Val running loss: 0.8721\n",
      "Epoch: 003, Train running loss: 0.8766, Val running loss: 0.8702\n",
      "Epoch: 004, Train running loss: 0.8749, Val running loss: 0.8684\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 7\u001b[0m     t_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     v_loss \u001b[38;5;241m=\u001b[39m evaluate(val_loader)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train running loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val running loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m----> 6\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking-new/lib/python3.11/site-packages/torch_geometric/data/data.py:262\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    259\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking-new/lib/python3.11/site-packages/torch_geometric/data/data.py:245\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 245\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking-new/lib/python3.11/site-packages/torch_geometric/data/storage.py:184\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking-new/lib/python3.11/site-packages/torch_geometric/data/storage.py:682\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 682\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/eddy-tracking-new/lib/python3.11/site-packages/torch_geometric/data/data.py:263\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    259\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t_loss = train()\n",
    "    v_loss = evaluate(val_loader)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train running loss: {t_loss:.4f}, Val running loss: {v_loss:.4f}')\n",
    "    train_loss.append(t_loss)\n",
    "    valid_loss.append(v_loss)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Training Complete!\")\n",
    "\n",
    "metric = evaluate(test_loader)\n",
    "print(f'Metric for test: {metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07469213-20da-4a74-9219-4521d40a3855",
   "metadata": {},
   "source": [
    "### Comparison plot for train/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d123bb-cdf2-42fc-856a-cbed3dcf6c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(valid_loss, label='Validation loss')\n",
    "plt.legend(title=\"Loss type: \" + params['loss_op'])\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER+\"/train_val_losses_demo.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe13b1a-e3c5-475b-a213-c1bb1b7dbc8b",
   "metadata": {},
   "source": [
    "### Graphical comparison model prediction/ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d84f40-be8b-4000-b687-0c1e3683f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "DEVICE=torch.device('cpu')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e033e-9969-491a-ab5e-28800642c34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    batch = batch.to(DEVICE)\n",
    "    pred = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c03a6e-5ec6-477c-8861-df5e4c0cba1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mesh = xr.open_dataset(MESH_PATH)\n",
    "mesh_lon = mesh.lon[mesh.nodes].values\n",
    "mesh_lat = mesh.lat[mesh.nodes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb4196-350b-4cbc-b531-5856a8e45d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "this_target = batch.y[:mesh.dims['nodes_subset']]\n",
    "_, this_pred = torch.max(pred[:mesh.dims['nodes_subset']], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3880b4f-68e4-4e14-a327-8fa3bd407277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "im = axes[0].scatter(mesh_lon, mesh_lat, c=this_target, s=1)\n",
    "im2 = axes[1].scatter(mesh_lon, mesh_lat, c=this_pred, s=1)\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER + \"/pred_vs_ground_demo.png\")\n",
    "    plt.close()\n",
    "\n",
    "time_func.stop_time(timestamp, \"pred_vs_ground plot created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015415e-df6a-4d72-9239-0cdd6c971e96",
   "metadata": {},
   "source": [
    "### Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e5b16-2487-413d-9dc1-94fdb6eb63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it on cuda is a huge improvement\n",
    "DEVICE=torch.device('cuda')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3276d-c915-48e5-96a6-bff9b4451509",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tot_background = 0\n",
    "    correct_pred = 0\n",
    "    tot_pred = len(test_loader.dataset)*dummy_graph.num_nodes\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        pred = model(batch)\n",
    "\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "\n",
    "        tot_background += (batch.y == 0).sum().item()\n",
    "\n",
    "        # This works because the values in the indices correspond to the values in batch.y\n",
    "        correct_pred += (indices == batch.y).sum().item()\n",
    "\n",
    "    print(f\"Total background cells:\\t{tot_background}\")\n",
    "    print(f\"Correct predictions:\\t{correct_pred}\")\n",
    "    print(f\"Total predictions:\\t{tot_pred}\")\n",
    "    print(f\"Graph U-Net accuracy:\\t{correct_pred/tot_pred*100:.2f}%\")\n",
    "\n",
    "time_func.stop_time(timestamp, \"Accuracy calculated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy-tracking-new",
   "language": "python",
   "name": "eddy-tracking-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
