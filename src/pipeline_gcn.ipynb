{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed79f1c-2767-4d8d-8988-f7d1cf29ec72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import summary\n",
    "import xarray as xr\n",
    "import yaml\n",
    "\n",
    "import Dataset\n",
    "import Models\n",
    "import Loss\n",
    "from utils import time_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a033a6e-d7e1-43a4-8556-ec00b1761f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cu121\n",
      "Cuda available: True\n",
      "Cuda device: NVIDIA A100-SXM4-40GB\n",
      "Cuda version: 12.1\n",
      "Torch geometric version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Cuda device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Cuda version: {torch.version.cuda}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335227eb-02db-4fb9-85a6-4af3562ca297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32eb1309-2482-472b-aac9-799c45dca7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open('./config/pipeline.yaml'))\n",
    "\n",
    "DATA_PATH = params['input_subset_pre_processed']\n",
    "MESH_PATH = params['input_subset_grid']\n",
    "\n",
    "DATASET_SIZE = params['dataset_size']\n",
    "\n",
    "TRAIN_PROP = params['train_prop']\n",
    "VAL_PROP = params['val_prop']\n",
    "TEST_PROP = params['test_prop']\n",
    "TRAIN_VAL_TEST = [TRAIN_PROP, VAL_PROP, TEST_PROP]\n",
    "\n",
    "TRAIN_BATCH_SIZE = params['train_batch_size']\n",
    "VAL_BATCH_SIZE = params['val_batch_size']\n",
    "TEST_BATCH_SIZE = params['test_batch_size']\n",
    "\n",
    "N_FEATURES = params['n_features']\n",
    "HID_CHANNELS = params['hid_channels']\n",
    "N_CLASSES = params['n_classes']\n",
    "N_LAYERS = params['n_layers']\n",
    "\n",
    "FINAL_ACT = None\n",
    "if params['final_act'] == \"sigmoid\":\n",
    "    FINAL_ACT = torch.sigmoid\n",
    "elif params['final_act'] == \"softmax\":\n",
    "    FINAL_ACT = torch.softmax\n",
    "elif params['final_act'] == \"linear\":\n",
    "    FINAL_ACT = torch.nn.Linear(1, 1)\n",
    "class_weights = [params['loss_weight_1'], params['loss_weight_2'], params['loss_weight_3']]\n",
    "LOSS_OP = None\n",
    "if params['loss_op'] == \"CE\":\n",
    "    LOSS_OP = torch.nn.CrossEntropyLoss()\n",
    "elif params['loss_op'] == \"WCE\":\n",
    "    LOSS_OP = Loss.WeightedCrossEntropyLoss(class_weights, DEVICE)\n",
    "elif params['loss_op'] == \"Focal\":\n",
    "    LOSS_OP = Loss.FocalLoss()\n",
    "elif params['loss_op'] == \"Dice\":\n",
    "    LOSS_OP = Loss.SoftDiceLoss(class_weights)\n",
    "elif params['loss_op'] == \"Tversky\":\n",
    "    LOSS_OP = Loss.TverskyLoss(alpha=0.3, beta=0.7, smooth=1.0, class_weights=class_weights)\n",
    "elif params['loss_op'] == \"TverskyDice\":\n",
    "    LOSS_OP = Loss.TverskyDiceLoss(alpha=0.3, beta=0.7, smooth=1.0, class_weights=class_weights)\n",
    "    \n",
    "OPTIMIZER = None\n",
    "if params['optimizer'] == \"Adam\":\n",
    "    OPTIMIZER = torch.optim.Adam\n",
    "\n",
    "LEARN_RATE = params['learn_rate']\n",
    "\n",
    "EPOCHS = params['epochs']\n",
    "\n",
    "PLOT_SHOW = params['plot_show']\n",
    "PLOT_FOLDER = params['output_images_path']\n",
    "\n",
    "TIMESTAMP = time_func.start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8009f87-209a-4138-9f7d-9428780d3b3f",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcbd3fe-b76f-49eb-9921-24a6013db352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for train-val-test split: 5743\n",
      "    Shape of node feature matrix: torch.Size([239536, 1])\n",
      "    Shape of graph connectivity in COO format: torch.Size([2, 1432160])\n",
      "    Shape of labels: torch.Size([239536])\n",
      "  ---  Datasets creation  ---  8.460 seconds.\n"
     ]
    }
   ],
   "source": [
    "random_seed = random.randint(1, 10000)\n",
    "print(f\"Random seed for train-val-test split: {random_seed}\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='train', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "val_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='val', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "test_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='test', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Datasets creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e716ee0-b006-4e55-a44f-73a6e30de341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 36 37\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.len(), val_dataset.len(), test_dataset.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a9bc78-057a-40af-a400-8e36e1f95f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataset[0]\\n\\ntimestamp = time_func.start_time()\\nfeatures_list = [data.x for data in train_dataset]\\nprint(np.shape(features_list))\\ntime_func.stop_time(timestamp, \"features in a list!\")\\n\\ntimestamp = time_func.start_time()\\nall_features = torch.cat(features_list, dim=0)\\ntime_func.stop_time(timestamp, \"features concatenated!\")\\n\\nall_features.shape\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dataset[0]\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "features_list = [data.x for data in train_dataset]\n",
    "print(np.shape(features_list))\n",
    "time_func.stop_time(timestamp, \"features in a list!\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "all_features = torch.cat(features_list, dim=0)\n",
    "time_func.stop_time(timestamp, \"features concatenated!\")\n",
    "\n",
    "all_features.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4aa208-7f54-4ee7-8a40-cfd179636e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nglobal_mean = all_features.mean(dim=0)\\nglobal_std = all_features.std(dim=0)\\nprint(f\"Mean: {global_mean}\\nStd: {global_std}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "global_mean = all_features.mean(dim=0)\n",
    "global_std = all_features.std(dim=0)\n",
    "print(f\"Mean: {global_mean}\\nStd: {global_std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fdc3a82-7a16-4c77-b0e7-a14bce563fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torch_geometric.transforms import NormalizeFeatures\\ntransform = NormalizeFeatures()\\n\\nprint(train_dataset[0].x)\\n\\ntimestamp = time_func.start_time()\\n\\ntrain_dataset = [transform(data) for data in train_dataset]\\nval_dataset = [transform(data) for data in val_dataset]\\ntest_dataset = [transform(data) for data in test_dataset]\\n\\ntime_func.stop_time(timestamp, \"features normalized!\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "transform = NormalizeFeatures()\n",
    "\n",
    "print(train_dataset[0].x)\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = [transform(data) for data in train_dataset]\n",
    "val_dataset = [transform(data) for data in val_dataset]\n",
    "test_dataset = [transform(data) for data in test_dataset]\n",
    "\n",
    "time_func.stop_time(timestamp, \"features normalized!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10ebd8a-3705-41c5-81a2-a0711bafc7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = [data.x for data in train_dataset]\\nall_features = torch.cat(features, dim=0)\\nmean = all_features.mean(dim=0)\\nstd = all_features.std(dim=0)\\nprint(f\"Mean: {mean}\\nStd: {std}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "features = [data.x for data in train_dataset]\n",
    "all_features = torch.cat(features, dim=0)\n",
    "mean = all_features.mean(dim=0)\n",
    "std = all_features.std(dim=0)\n",
    "print(f\"Mean: {mean}\\nStd: {std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65efdf-cfde-4feb-8cd3-f240636c1c34",
   "metadata": {},
   "source": [
    "### Testing some parameters and orientation of graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764f45a6-dfe7-4fa7-b892-5dbc756db97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (TRAIN_PROP+VAL_PROP+TEST_PROP) != 100:\n",
    "    raise ValueError(f\"Sum of train-val-test proportions with value {TRAIN_PROP+VAL_PROP+TEST_PROP} is different from 100\")\n",
    "\n",
    "if FINAL_ACT == None:\n",
    "    raise ValueError(f\"Parameter 'final_act' is invalid with value {params['final_act']}\")\n",
    "\n",
    "if LOSS_OP == None:\n",
    "    if params['loss_op'] != \"Dice\":\n",
    "        raise ValueError(f\"Parameter 'loss_op' is invalid with value {params['loss_op']}\")\n",
    "\n",
    "if OPTIMIZER == None:\n",
    "    raise ValueError(f\"Parameter 'optimizer' is invalid with value {params['optimizer']}\")\n",
    "\n",
    "dummy_graph = train_dataset[0]\n",
    "\n",
    "if dummy_graph.num_features != N_FEATURES:\n",
    "    raise ValueError(f\"Graph num_features is different from parameter N_FEATURES: ({dummy_graph.num_features} != {N_FEATURES})\")\n",
    "\n",
    "if dummy_graph.is_directed():\n",
    "    raise ValueError(\"Graph edges are directed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b756f7-7799-4dc8-b40a-aaef3b1ce904",
   "metadata": {},
   "source": [
    "### Train-validation-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d40cf8d-1eb2-4177-9830-0fac421de7de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 36 37\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3de1d-9864-4536-b634-e05635056e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6db1ea-a1d4-4793-a665-838c3df37dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNModel(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): GCNConv(1, 32)\n",
       "    (1-3): 3 x GCNConv(32, 32)\n",
       "    (4): GCNConv(32, 3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = Models.GCNModel\n",
    "\n",
    "model = Model(\n",
    "    num_features = N_FEATURES,\n",
    "    hidden_dim = HID_CHANNELS,\n",
    "    num_classes = N_CLASSES,\n",
    "    num_layers = N_LAYERS,\n",
    "    num_nodes = dummy_graph.num_nodes,   # TODO can put these in Dataset.py\n",
    "    final_act = FINAL_ACT\n",
    ").to(DEVICE)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39dc66b-4924-4ada-862c-e75be6e678f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------------------------+----------------+----------+\n",
      "| Layer                     | Input Shape                | Output Shape   | #Param   |\n",
      "|---------------------------+----------------------------+----------------+----------|\n",
      "| GCNModel                  | [239536, 239536]           | [239536, 3]    | 3,331    |\n",
      "| ├─(conv_layers)ModuleList | --                         | --             | 3,331    |\n",
      "| │    └─(0)GCNConv         | [239536, 1], [2, 1432160]  | [239536, 32]   | 64       |\n",
      "| │    └─(1)GCNConv         | [239536, 32], [2, 1432160] | [239536, 32]   | 1,056    |\n",
      "| │    └─(2)GCNConv         | [239536, 32], [2, 1432160] | [239536, 32]   | 1,056    |\n",
      "| │    └─(3)GCNConv         | [239536, 32], [2, 1432160] | [239536, 32]   | 1,056    |\n",
      "| │    └─(4)GCNConv         | [239536, 32], [2, 1432160] | [239536, 3]    | 99       |\n",
      "+---------------------------+----------------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "dummy_graph.to(DEVICE)\n",
    "print(summary(model, dummy_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09936-0b86-4ac6-83a9-014239ce3675",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c4bc3e-ff40-44eb-8e85-21bf090eaa05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = OPTIMIZER(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3a2a4-6840-412e-a0fb-17c9b68faecc",
   "metadata": {},
   "source": [
    "### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3555c5e-5132-4c9e-ac2f-93d626e96c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ---  Unique counted!  ---  13.499 seconds.\n",
      "[1.1468968602862453, 14.861141429462894, 16.449415899966535] - freq_inv\n",
      "[0.03533539178958915, 0.45786528242784147, 0.5067993257825694] - class_weights\n"
     ]
    }
   ],
   "source": [
    "if params['loss_op'] == \"Dice\":\n",
    "    \n",
    "    timestamp = time_func.start_time()\n",
    "\n",
    "    tot_counts = [0, 0, 0]\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        \n",
    "        unique, counts = torch.unique(batch.y, return_counts=True)\n",
    "        \n",
    "        # TODO - I don't really like this, it just informs me whether something is wrong and then does it anyway\n",
    "        if 0 not in unique:\n",
    "            print(\"Error: class 0 not present in batch\")\n",
    "        elif 1 not in unique:\n",
    "            print(\"Error: class 1 not present in batch\")\n",
    "        elif 2 not in unique:\n",
    "            print(\"Error: class 2 not present in batch\")\n",
    "        else:\n",
    "            for class_idx in unique:\n",
    "                tot_counts[class_idx] += counts[class_idx].item()\n",
    "\n",
    "    time_func.stop_time(timestamp, \"Unique counted!\")\n",
    "    \n",
    "    freq = [c/np.sum(tot_counts) for c in tot_counts]\n",
    "    freq_inv = [1/f for f in freq]\n",
    "    class_weights = [f/np.sum(freq_inv) for f in freq_inv]\n",
    "    print(freq_inv, \"- freq_inv\")\n",
    "    print(class_weights, \"- class_weights\")\n",
    "    LOSS_OP = Loss.SoftDiceLoss(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dba108-aab1-4308-8ef1-f9af1595b818",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5d99c5-5c07-494b-8eb4-849741d46173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "        \n",
    "        # If you try the Soft Dice Score, use this(even if the loss stays constant)\n",
    "        #loss.requires_grad = True\n",
    "        #loss = torch.tensor(loss.item(), requires_grad=True)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        \n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191eccf-0b3e-4e2f-9eb8-d0b68e2f5aa8",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c067d1ee-f24b-41e5-8fd4-6de0f9546ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    \n",
    "    average_loss = total_loss / len(loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c0bd0-d87d-407a-a00f-c3b1baeb6075",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computation time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5fb713-fda3-40bd-b729-be63ec773546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ---  Computation before training finished!  ---  23.455 seconds.\n"
     ]
    }
   ],
   "source": [
    "time_func.stop_time(TIMESTAMP, \"Computation before training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e39fb6f-6f39-4071-9271-ae684ba04d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom time import time\\nimport multiprocessing as mp\\n\\nfor num_workers in range(2, mp.cpu_count(), 2):\\n    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\\n    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\\n\\n    start = time()\\n    for epoch in range(1, 3):\\n        for i, data in enumerate(train_loader, 0):\\n            pass\\n        for i, data in enumerate(val_loader, 0):\\n            pass\\n    end = time()\\n    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "for num_workers in range(2, mp.cpu_count(), 2):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8995f5-2bb4-4fee-bc5d-523333087f5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Epoch training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa97935-88b2-411b-aec5-c21441b0d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.64 GiB. GPU 0 has a total capacty of 39.39 GiB of which 2.54 GiB is free. Process 756407 has 28.11 GiB memory in use. Including non-PyTorch memory, this process has 8.67 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 7\u001b[0m     t_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     v_loss \u001b[38;5;241m=\u001b[39m evaluate(val_loader)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train running loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val running loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m OPTIMIZER\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# forward + loss\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m LOSS_OP(pred, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# If you try the Soft Dice Score, use this(even if the loss stays constant)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#loss.requires_grad = True\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#loss = torch.tensor(loss.item(), requires_grad=True)\u001b[39;00m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/eddiesGNN/src/Models.py:84\u001b[0m, in \u001b[0;36mGCNModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(data\u001b[38;5;241m.\u001b[39mx, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.92\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers:\n\u001b[0;32m---> 84\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_final\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:244\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    241\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:463\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 463\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    465\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/work/ab0995/b382484/conda/pkgs/eddy-tracking/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:253\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.64 GiB. GPU 0 has a total capacty of 39.39 GiB of which 2.54 GiB is free. Process 756407 has 28.11 GiB memory in use. Including non-PyTorch memory, this process has 8.67 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t_loss = train()\n",
    "    v_loss = evaluate(val_loader)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train running loss: {t_loss:.4f}, Val running loss: {v_loss:.4f}')\n",
    "    train_loss.append(t_loss)\n",
    "    valid_loss.append(v_loss)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Training Complete!\")\n",
    "\n",
    "metric = evaluate(test_loader)\n",
    "print(f'Metric for test: {metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07469213-20da-4a74-9219-4521d40a3855",
   "metadata": {},
   "source": [
    "### Comparison plot for train/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d123bb-cdf2-42fc-856a-cbed3dcf6c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(valid_loss, label='Validation loss')\n",
    "plt.legend(title=\"Loss type: \" + params['loss_op'])\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER+\"/train_val_losses_demo.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe13b1a-e3c5-475b-a213-c1bb1b7dbc8b",
   "metadata": {},
   "source": [
    "### Graphical comparison model prediction/ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d84f40-be8b-4000-b687-0c1e3683f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "DEVICE=torch.device('cpu')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e033e-9969-491a-ab5e-28800642c34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    batch = batch.to(DEVICE)\n",
    "    pred = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c03a6e-5ec6-477c-8861-df5e4c0cba1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mesh = xr.open_dataset(MESH_PATH)\n",
    "mesh_lon = mesh.lon[mesh.nodes].values\n",
    "mesh_lat = mesh.lat[mesh.nodes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb4196-350b-4cbc-b531-5856a8e45d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "this_target = batch.y[:mesh.dims['nodes_subset']]\n",
    "_, this_pred = torch.max(pred[:mesh.dims['nodes_subset']], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3880b4f-68e4-4e14-a327-8fa3bd407277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "im = axes[0].scatter(mesh_lon, mesh_lat, c=this_target, s=1)\n",
    "im2 = axes[1].scatter(mesh_lon, mesh_lat, c=this_pred, s=1)\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER + \"/pred_vs_ground_demo.png\")\n",
    "    plt.close()\n",
    "\n",
    "time_func.stop_time(timestamp, \"pred_vs_ground plot created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015415e-df6a-4d72-9239-0cdd6c971e96",
   "metadata": {},
   "source": [
    "### Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e5b16-2487-413d-9dc1-94fdb6eb63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it on cuda is a huge improvement\n",
    "DEVICE=torch.device('cuda')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3276d-c915-48e5-96a6-bff9b4451509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tot_background = 0\n",
    "    correct_pred = 0\n",
    "    tot_pred = len(test_loader.dataset)*dummy_graph.num_nodes\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        pred = model(batch)\n",
    "\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "\n",
    "        tot_background += (batch.y == 0).sum().item()\n",
    "\n",
    "        # This works because the values in the indices correspond to the values in batch.y\n",
    "        correct_pred += (indices == batch.y).sum().item()\n",
    "\n",
    "    print(f\"Total background cells:\\t{tot_background}\")\n",
    "    print(f\"Correct predictions:\\t{correct_pred}\")\n",
    "    print(f\"Total predictions:\\t{tot_pred}\")\n",
    "    print(f\"GCN accuracy:\\t{correct_pred/tot_pred*100:.2f}%\")\n",
    "\n",
    "time_func.stop_time(timestamp, \"Accuracy calculated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730ac9c-2ea6-4346-bae8-2adc69581643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model's state dictionary to a file\n",
    "#PATH = \"gcn_modelone.pth\"\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ac2c5-c89d-419a-8c02-0b0b3c01fe86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "<eddy-tracking",
   "language": "python",
   "name": "eddy-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
