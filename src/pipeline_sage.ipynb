{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed79f1c-2767-4d8d-8988-f7d1cf29ec72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import summary\n",
    "import xarray as xr\n",
    "import yaml\n",
    "\n",
    "import Dataset\n",
    "import Models\n",
    "import Loss\n",
    "from utils import time_func\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a033a6e-d7e1-43a4-8556-ec00b1761f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cu121\n",
      "Cuda available: True\n",
      "Cuda device: NVIDIA A100-SXM4-40GB\n",
      "Cuda version: 12.1\n",
      "Torch geometric version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Cuda device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Cuda version: {torch.version.cuda}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335227eb-02db-4fb9-85a6-4af3562ca297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32eb1309-2482-472b-aac9-799c45dca7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open('./config/pipeline.yaml'))\n",
    "\n",
    "DATA_PATH = params['input_subset_pre_processed']\n",
    "MESH_PATH = params['input_subset_grid']\n",
    "\n",
    "DATASET_SIZE = params['dataset_size']\n",
    "\n",
    "TRAIN_PROP = params['train_prop']\n",
    "VAL_PROP = params['val_prop']\n",
    "TEST_PROP = params['test_prop']\n",
    "TRAIN_VAL_TEST = [TRAIN_PROP, VAL_PROP, TEST_PROP]\n",
    "\n",
    "TRAIN_BATCH_SIZE = params['train_batch_size']\n",
    "VAL_BATCH_SIZE = params['val_batch_size']\n",
    "TEST_BATCH_SIZE = params['test_batch_size']\n",
    "\n",
    "N_FEATURES = params['n_features']\n",
    "HID_CHANNELS = params['hid_channels']\n",
    "N_CLASSES = params['n_classes']\n",
    "N_LAYERS = params['n_layers']\n",
    "\n",
    "FINAL_ACT = None\n",
    "if params['final_act'] == \"sigmoid\":\n",
    "    FINAL_ACT = torch.sigmoid\n",
    "elif params['final_act'] == \"softmax\":\n",
    "    FINAL_ACT = torch.softmax\n",
    "elif params['final_act'] == \"linear\":\n",
    "    FINAL_ACT = torch.nn.Linear(1, 1)\n",
    "\n",
    "class_weights = [params['loss_weight_1'], params['loss_weight_2'], params['loss_weight_3']]\n",
    "LOSS_OP = None\n",
    "if params['loss_op'] == \"CE\":\n",
    "    LOSS_OP = torch.nn.CrossEntropyLoss()\n",
    "elif params['loss_op'] == \"WCE\":\n",
    "    LOSS_OP = Loss.WeightedCrossEntropyLoss(class_weights, DEVICE)\n",
    "elif params['loss_op'] == \"Focal\":\n",
    "    LOSS_OP = Loss.FocalLoss()\n",
    "elif params['loss_op'] == \"Dice\":\n",
    "    LOSS_OP = Loss.SoftDiceLoss(class_weights)\n",
    "elif params['loss_op'] == \"Tversky\":\n",
    "    LOSS_OP = Loss.TverskyLoss(alpha=0.3, beta=0.7, smooth=1.0, class_weights=class_weights)\n",
    "elif params['loss_op'] == \"TverskyDice\":\n",
    "    LOSS_OP = Loss.TverskyDiceLoss(alpha=0.3, beta=0.7, smooth=1.0, class_weights=class_weights)\n",
    "    \n",
    "OPTIMIZER = None\n",
    "if params['optimizer'] == \"Adam\":\n",
    "    OPTIMIZER = torch.optim.Adam\n",
    "\n",
    "LEARN_RATE = params['learn_rate']\n",
    "\n",
    "EPOCHS = params['epochs']\n",
    "\n",
    "PLOT_SHOW = params['plot_show']\n",
    "PLOT_FOLDER = params['output_images_path']\n",
    "\n",
    "TIMESTAMP = time_func.start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8009f87-209a-4138-9f7d-9428780d3b3f",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcbd3fe-b76f-49eb-9921-24a6013db352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for train-val-test split: 3291\n",
      "    Shape of node feature matrix: torch.Size([239536, 1])\n",
      "    Shape of graph connectivity in COO format: torch.Size([2, 1432160])\n",
      "    Shape of labels: torch.Size([239536])\n",
      "  ---  Datasets creation  ---  2.475 seconds.\n"
     ]
    }
   ],
   "source": [
    "random_seed = random.randint(1, 10000)\n",
    "print(f\"Random seed for train-val-test split: {random_seed}\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='train', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "val_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='val', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "test_dataset = Dataset.EddyDataset(root=DATA_PATH, mesh_path=MESH_PATH, dataset_size=DATASET_SIZE, split='test', proportions=TRAIN_VAL_TEST, random_seed=random_seed)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Datasets creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e716ee0-b006-4e55-a44f-73a6e30de341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 10 10\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.len(), val_dataset.len(), test_dataset.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a9bc78-057a-40af-a400-8e36e1f95f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataset[0]\\n\\ntimestamp = time_func.start_time()\\nfeatures_list = [data.x for data in train_dataset]\\nprint(np.shape(features_list))\\ntime_func.stop_time(timestamp, \"features in a list!\")\\n\\ntimestamp = time_func.start_time()\\nall_features = torch.cat(features_list, dim=0)\\ntime_func.stop_time(timestamp, \"features concatenated!\")\\n\\nall_features.shape\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dataset[0]\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "features_list = [data.x for data in train_dataset]\n",
    "print(np.shape(features_list))\n",
    "time_func.stop_time(timestamp, \"features in a list!\")\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "all_features = torch.cat(features_list, dim=0)\n",
    "time_func.stop_time(timestamp, \"features concatenated!\")\n",
    "\n",
    "all_features.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4aa208-7f54-4ee7-8a40-cfd179636e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nglobal_mean = all_features.mean(dim=0)\\nglobal_std = all_features.std(dim=0)\\nprint(f\"Mean: {global_mean}\\nStd: {global_std}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "global_mean = all_features.mean(dim=0)\n",
    "global_std = all_features.std(dim=0)\n",
    "print(f\"Mean: {global_mean}\\nStd: {global_std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fdc3a82-7a16-4c77-b0e7-a14bce563fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torch_geometric.transforms import NormalizeFeatures\\ntransform = NormalizeFeatures()\\n\\nprint(train_dataset[0].x)\\n\\ntimestamp = time_func.start_time()\\n\\ntrain_dataset = [transform(data) for data in train_dataset]\\nval_dataset = [transform(data) for data in val_dataset]\\ntest_dataset = [transform(data) for data in test_dataset]\\n\\ntime_func.stop_time(timestamp, \"features normalized!\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "transform = NormalizeFeatures()\n",
    "\n",
    "print(train_dataset[0].x)\n",
    "\n",
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_dataset = [transform(data) for data in train_dataset]\n",
    "val_dataset = [transform(data) for data in val_dataset]\n",
    "test_dataset = [transform(data) for data in test_dataset]\n",
    "\n",
    "time_func.stop_time(timestamp, \"features normalized!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10ebd8a-3705-41c5-81a2-a0711bafc7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = [data.x for data in train_dataset]\\nall_features = torch.cat(features, dim=0)\\nmean = all_features.mean(dim=0)\\nstd = all_features.std(dim=0)\\nprint(f\"Mean: {mean}\\nStd: {std}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "features = [data.x for data in train_dataset]\n",
    "all_features = torch.cat(features, dim=0)\n",
    "mean = all_features.mean(dim=0)\n",
    "std = all_features.std(dim=0)\n",
    "print(f\"Mean: {mean}\\nStd: {std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65efdf-cfde-4feb-8cd3-f240636c1c34",
   "metadata": {},
   "source": [
    "### Testing some parameters and orientation of graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764f45a6-dfe7-4fa7-b892-5dbc756db97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (TRAIN_PROP+VAL_PROP+TEST_PROP) != 100:\n",
    "    raise ValueError(f\"Sum of train-val-test proportions with value {TRAIN_PROP+VAL_PROP+TEST_PROP} is different from 100\")\n",
    "\n",
    "if FINAL_ACT == None:\n",
    "    raise ValueError(f\"Parameter 'final_act' is invalid with value {params['final_act']}\")\n",
    "\n",
    "if LOSS_OP == None:\n",
    "    raise ValueError(f\"Parameter 'loss_op' is invalid with value {params['loss_op']}\")\n",
    "\n",
    "if OPTIMIZER == None:\n",
    "    raise ValueError(f\"Parameter 'optimizer' is invalid with value {params['optimizer']}\")\n",
    "\n",
    "dummy_graph = train_dataset[0]\n",
    "\n",
    "if dummy_graph.num_features != N_FEATURES:\n",
    "    raise ValueError(f\"Graph num_features is different from parameter N_FEATURES: ({dummy_graph.num_features} != {N_FEATURES})\")\n",
    "\n",
    "if dummy_graph.is_directed():\n",
    "    raise ValueError(\"Graph edges are directed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b756f7-7799-4dc8-b40a-aaef3b1ce904",
   "metadata": {},
   "source": [
    "### Train-validation-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d40cf8d-1eb2-4177-9830-0fac421de7de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 10 10\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3de1d-9864-4536-b634-e05635056e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6db1ea-a1d4-4793-a665-838c3df37dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGEModel(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): SAGEConv(1, 64, aggr=mean)\n",
       "    (1-7): 7 x SAGEConv(64, 64, aggr=mean)\n",
       "    (8): SAGEConv(64, 3, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSAGE = Models.GraphSAGEModel\n",
    "model = ModelSAGE(\n",
    "    num_features = N_FEATURES,\n",
    "    hidden_dim = HID_CHANNELS,\n",
    "    num_classes = N_CLASSES,\n",
    "    num_layers = N_LAYERS,\n",
    "    num_nodes = dummy_graph.num_nodes,   # TODO can put these in Dataset.py\n",
    "    final_act = FINAL_ACT\n",
    "    #num_nodes = dummy_graph.num_nodes   # TODO can put these in Dataset.py\n",
    "    #final_act = FINAL_ACT\n",
    ").to(DEVICE)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39dc66b-4924-4ada-862c-e75be6e678f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------------------------+----------------+----------+\n",
      "| Layer                     | Input Shape                | Output Shape   | #Param   |\n",
      "|---------------------------+----------------------------+----------------+----------|\n",
      "| GraphSAGEModel            | [239536, 239536]           | [239536, 3]    | 58,371   |\n",
      "| ├─(conv_layers)ModuleList | --                         | --             | 58,371   |\n",
      "| │    └─(0)SAGEConv        | [239536, 1], [2, 1432160]  | [239536, 64]   | 192      |\n",
      "| │    └─(1)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(2)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(3)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(4)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(5)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(6)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(7)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 64]   | 8,256    |\n",
      "| │    └─(8)SAGEConv        | [239536, 64], [2, 1432160] | [239536, 3]    | 387      |\n",
      "+---------------------------+----------------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "dummy_graph.to(DEVICE)\n",
    "print(summary(model, dummy_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09936-0b86-4ac6-83a9-014239ce3675",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c4bc3e-ff40-44eb-8e85-21bf090eaa05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTIMIZER = OPTIMIZER(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3a2a4-6840-412e-a0fb-17c9b68faecc",
   "metadata": {},
   "source": [
    "### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3555c5e-5132-4c9e-ac2f-93d626e96c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params['loss_op'] == \"Dice\":\n",
    "    \n",
    "    timestamp = time_func.start_time()\n",
    "\n",
    "    tot_counts = [0, 0, 0]\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        \n",
    "        unique, counts = torch.unique(batch.y, return_counts=True)\n",
    "        \n",
    "        # TODO - I don't really like this, it just informs me whether something is wrong and then does it anyway\n",
    "        if 0 not in unique:\n",
    "            print(\"Error: class 0 not present in batch\")\n",
    "        elif 1 not in unique:\n",
    "            print(\"Error: class 1 not present in batch\")\n",
    "        elif 2 not in unique:\n",
    "            print(\"Error: class 2 not present in batch\")\n",
    "        else:\n",
    "            for class_idx in unique:\n",
    "                tot_counts[class_idx] += counts[class_idx].item()\n",
    "\n",
    "    time_func.stop_time(timestamp, \"Unique counted!\")\n",
    "    \n",
    "    freq = [c/np.sum(tot_counts) for c in tot_counts]\n",
    "    freq_inv = [1/f for f in freq]\n",
    "    class_weights = [f/np.sum(freq_inv) for f in freq_inv]\n",
    "    print(freq_inv, \"- freq_inv\")\n",
    "    print(class_weights, \"- class_weights\")\n",
    "    LOSS_OP = Loss.SoftDiceLoss(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dba108-aab1-4308-8ef1-f9af1595b818",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5d99c5-5c07-494b-8eb4-849741d46173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "        \n",
    "        # If you try the Soft Dice Score, use this(even if the loss stays constant)\n",
    "        #loss.requires_grad = True\n",
    "        #loss = torch.tensor(loss.item(), requires_grad=True)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        \n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191eccf-0b3e-4e2f-9eb8-d0b68e2f5aa8",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c067d1ee-f24b-41e5-8fd4-6de0f9546ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # forward + loss\n",
    "        pred = model(batch)\n",
    "        loss = LOSS_OP(pred, batch.y)\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    \n",
    "    average_loss = total_loss / len(loader.dataset)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c0bd0-d87d-407a-a00f-c3b1baeb6075",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computation time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5fb713-fda3-40bd-b729-be63ec773546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ---  Computation before training finished!  ---  3.573 seconds.\n"
     ]
    }
   ],
   "source": [
    "time_func.stop_time(TIMESTAMP, \"Computation before training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e39fb6f-6f39-4071-9271-ae684ba04d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom time import time\\nimport multiprocessing as mp\\n\\nfor num_workers in range(2, mp.cpu_count(), 2):\\n    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\\n    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\\n\\n    start = time()\\n    for epoch in range(1, 3):\\n        for i, data in enumerate(train_loader, 0):\\n            pass\\n        for i, data in enumerate(val_loader, 0):\\n            pass\\n    end = time()\\n    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "for num_workers in range(2, mp.cpu_count(), 2):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with: {} second, num_workers={}\".format(end - start, num_workers))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8995f5-2bb4-4fee-bc5d-523333087f5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Epoch training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa97935-88b2-411b-aec5-c21441b0d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t_loss = train()\n",
    "    v_loss = evaluate(val_loader)\n",
    "    print(f'Epoch: {epoch+1:03d}, Train running loss: {t_loss:.4f}, Val running loss: {v_loss:.4f}')\n",
    "    train_loss.append(t_loss)\n",
    "    valid_loss.append(v_loss)\n",
    "\n",
    "time_func.stop_time(timestamp, \"Training Complete!\")\n",
    "\n",
    "metric = evaluate(test_loader)\n",
    "print(f'Metric for test: {metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07469213-20da-4a74-9219-4521d40a3855",
   "metadata": {},
   "source": [
    "### Comparison plot for train/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d123bb-cdf2-42fc-856a-cbed3dcf6c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(valid_loss, label='Validation loss')\n",
    "plt.legend(title=\"Loss type: \" + params['loss_op'])\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER+\"/train_val_losses_demo.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe13b1a-e3c5-475b-a213-c1bb1b7dbc8b",
   "metadata": {},
   "source": [
    "### Graphical comparison model prediction/ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d84f40-be8b-4000-b687-0c1e3683f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "DEVICE=torch.device('cpu')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e033e-9969-491a-ab5e-28800642c34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    batch = batch.to(DEVICE)\n",
    "    pred = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c03a6e-5ec6-477c-8861-df5e4c0cba1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mesh = xr.open_dataset(MESH_PATH)\n",
    "mesh_lon = mesh.lon[mesh.nodes].values\n",
    "mesh_lat = mesh.lat[mesh.nodes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb4196-350b-4cbc-b531-5856a8e45d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "this_target = batch.y[:mesh.dims['nodes_subset']]\n",
    "_, this_pred = torch.max(pred[:mesh.dims['nodes_subset']], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3880b4f-68e4-4e14-a327-8fa3bd407277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "im = axes[0].scatter(mesh_lon, mesh_lat, c=this_target, s=1)\n",
    "im2 = axes[1].scatter(mesh_lon, mesh_lat, c=this_pred, s=1)\n",
    "\n",
    "if PLOT_SHOW:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(PLOT_FOLDER + \"/pred_vs_ground_demo.png\")\n",
    "    plt.close()\n",
    "\n",
    "time_func.stop_time(timestamp, \"pred_vs_ground plot created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015415e-df6a-4d72-9239-0cdd6c971e96",
   "metadata": {},
   "source": [
    "### Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e5b16-2487-413d-9dc1-94fdb6eb63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it on cuda is a huge improvement\n",
    "DEVICE=torch.device('cuda')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbefd69-2f59-450e-a47f-b93d24c72934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, targets):\n",
    "    # Convert predictions to binary (0 or 1) using a threshold (e.g., 0.5 for sigmoid activation)\n",
    "    binary_predictions = (predictions > 0.5).float()\n",
    "\n",
    "    # Flatten the predictions and targets to one-dimensional tensors\n",
    "    flat_predictions = binary_predictions.view(-1)\n",
    "    flat_targets = targets.view(-1)\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    predictions_np = flat_predictions.cpu().numpy()\n",
    "    targets_np = flat_targets.cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(targets_np, predictions_np)\n",
    "    recall = recall_score(targets_np, predictions_np)\n",
    "    f1 = f1_score(targets_np, predictions_np)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3276d-c915-48e5-96a6-bff9b4451509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tot_background = 0\n",
    "    correct_pred = 0\n",
    "    tot_pred = len(test_loader.dataset)*dummy_graph.num_nodes\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        pred = model(batch)\n",
    "\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "\n",
    "        tot_background += (batch.y == 0).sum().item()\n",
    "        precision, recall, f1 = calculate_metrics(pred, bach.y)\n",
    "\n",
    "        # Print or log the metrics\n",
    "        print(f'Epoch {epoch + 1}, Validation Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "\n",
    "        # This works because the values in the indices correspond to the values in batch.y\n",
    "        correct_pred += (indices == batch.y).sum().item()\n",
    "\n",
    "    print(f\"Total background cells:\\t{tot_background}\")\n",
    "    print(f\"Correct predictions:\\t{correct_pred}\")\n",
    "    print(f\"Total predictions:\\t{tot_pred}\")\n",
    "    print(f\"Graph Sage accuracy:\\t{correct_pred/tot_pred*100:.2f}%\")\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1 = calculate_metrics(pred, )\n",
    "\n",
    "    # Print or log the metrics\n",
    "    print(f'Epoch {epoch + 1}, Validation Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "time_func.stop_time(timestamp, \"Accuracy calculated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e102d97-ecaf-46c0-9bae-a077933a3255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = time_func.start_time()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tot_background = 0\n",
    "    predictions = []\n",
    "    tot_pred = len(test_loader.dataset)*dummy_graph.num_nodes\n",
    "    labels = []\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        pred = model(batch)\n",
    "\n",
    "        _, indices = torch.max(pred, dim=1)\n",
    "\n",
    "        tot_background += (batch.y == 0).sum().item()\n",
    "        labels = batch.y\n",
    "       \n",
    "time_func.stop_time(timestamp, \"Accuracy calculated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "<eddy-tracking",
   "language": "python",
   "name": "eddy-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
